{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "avKNSGAYeyMV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\" # 환경변수에 OPENAI_API_KEY를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1ytJZvlMe7oL"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
        "openai.api_key = \"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\" # 환경변수에 OPENAI_API_KEY를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aEhCZiv-fPQb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from termcolor import colored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YwuOYa1jfXE7"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
        "def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
        "    }\n",
        "    json_data = {\"model\": model, \"messages\": messages}\n",
        "    if functions is not None:\n",
        "        json_data.update({\"functions\": functions})\n",
        "    if function_call is not None:\n",
        "        json_data.update({\"function_call\": function_call})\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://api.openai.com/v1/chat/completions\",\n",
        "            headers=headers,\n",
        "            json=json_data,\n",
        "        )\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Unable to generate ChatCompletion response\")\n",
        "        print(f\"Exception: {e}\")\n",
        "        return e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eetw9yGDfpzc"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    {\n",
        "        \"name\": \"get_title_paper\",\n",
        "        \"description\": \"Get the titles of papers regarding provided subject\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"subject\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The subject of research\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"subject\"],\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qLd83Mixf-zk"
      },
      "outputs": [],
      "source": [
        "messages = []\n",
        "\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"의료 인공지능\"})\n",
        "\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions\n",
        ")\n",
        "\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "\n",
        "messages.append(assistant_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JWHuyItgVH7",
        "outputId": "8c19947c-d673-4c09-b188-cd5fcfbbd52a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'assistant',\n",
              " 'content': None,\n",
              " 'function_call': {'name': 'get_title_paper',\n",
              "  'arguments': '{\\n\"subject\": \"의료 인공지능\"\\n}'}}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assistant_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lhuJ_kVQidID"
      },
      "outputs": [],
      "source": [
        "response_message = assistant_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swoGa4u4jLU0",
        "outputId": "ad7d0b53-8b33-46d2-87e2-0ab77863b728"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'assistant',\n",
              " 'content': None,\n",
              " 'function_call': {'name': 'get_title_paper',\n",
              "  'arguments': '{\\n\"subject\": \"의료 인공지능\"\\n}'}}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ccZSkJxWjXpa"
      },
      "outputs": [],
      "source": [
        "def get_title_paper(subject):\n",
        "\n",
        "    #크롤링 결과\n",
        "    titles = \"언어, llm\"\n",
        "\n",
        "    return titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu0xYcDaieGa",
        "outputId": "03f45164-ce23-45b4-f414-01d408b1ebf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "언어, llm\n",
            "[{'role': 'system', 'content': \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"}, {'role': 'user', 'content': '의료 인공지능'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'get_title_paper', 'arguments': '{\\n\"subject\": \"의료 인공지능\"\\n}'}}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'get_title_paper', 'arguments': '{\\n\"subject\": \"의료 인공지능\"\\n}'}}, {'role': 'function', 'name': 'get_title_paper', 'content': '언어, llm'}]\n",
            "{\n",
            "  \"id\": \"chatcmpl-7pseMBHRoohaZ9nqopmfienBof1ye\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1692599158,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"\\uacc4\\uc18d \\uc9c4\\ud589\\ud558\\uae30 \\uc804\\uc5d0 \\uba87 \\uac00\\uc9c0 \\ucd94\\uac00 \\uc815\\ubcf4\\ub97c \\uc5bb\\uc744 \\uc218 \\uc788\\uc744\\uae4c\\uc694? \\\"\\uc758\\ub8cc \\uc778\\uacf5\\uc9c0\\ub2a5\\\"\\uc5d0 \\ub300\\ud574 \\uc5b4\\ub5a4 \\uc885\\ub958\\uc758 \\ub17c\\ubb38 \\uc81c\\ubaa9\\uc744 \\ucc3e\\uc73c\\uc2dc\\ub824\\uace0 \\ud558\\ub098\\uc694? \\uc608\\ub97c \\ub4e4\\uc5b4, \\uc758\\ub8cc \\uc778\\uacf5\\uc9c0\\ub2a5\\uc744 \\uc0ac\\uc6a9\\ud558\\uc5ec \\uc9c8\\ubcd1 \\uc9c4\\ub2e8\\uc5d0 \\ub300\\ud55c \\uc5f0\\uad6c\\ub098 \\uc758\\ub8cc \\uae30\\ub85d \\ubd84\\uc11d \\ub4f1\\uc5d0 \\uad00\\ud55c \\ub17c\\ubb38\\uc744 \\ucc3e\\uace0\\uc790 \\ud558\\uc2dc\\ub294 \\uac74\\uac00\\uc694? \\ub354 \\uad6c\\uccb4\\uc801\\uc778 \\ub0b4\\uc6a9\\uc744 \\uc54c\\ub824\\uc8fc\\uc2dc\\uba74 \\ub354\\uc6b1 \\ub3c4\\uc6c0\\uc744 \\ub4dc\\ub9b4 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 97,\n",
            "    \"completion_tokens\": 160,\n",
            "    \"total_tokens\": 257\n",
            "  }\n",
            "}\n",
            "계속 진행하기 전에 몇 가지 추가 정보를 얻을 수 있을까요? \"의료 인공지능\"에 대해 어떤 종류의 논문 제목을 찾으시려고 하나요? 예를 들어, 의료 인공지능을 사용하여 질병 진단에 대한 연구나 의료 기록 분석 등에 관한 논문을 찾고자 하시는 건가요? 더 구체적인 내용을 알려주시면 더욱 도움을 드릴 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        " # Step 2: check if GPT wanted to call a function\n",
        "if response_message.get(\"function_call\"):\n",
        "    # Step 3: call the function\n",
        "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "    available_functions = {\n",
        "        \"get_title_paper\": get_title_paper,\n",
        "    }  # only one function in this example, but you can have multiple\n",
        "    # 1. 함수 이름 획득\n",
        "    function_name = response_message[\"function_call\"][\"name\"]\n",
        "    # 2. 함수 이름으로 실제 함수 주소 획득\n",
        "    fuction_to_call = available_functions[function_name]\n",
        "\n",
        "    # 3. 인자 획득\n",
        "    function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
        "\n",
        "    # 4. 함수 호출 및 결과 획득 (함수 이름과 인자를 사용하여)\n",
        "    function_response = fuction_to_call(\n",
        "        subject=function_args.get(\"subject\"),\n",
        "    )\n",
        "\n",
        "    print(function_response)\n",
        "\n",
        "    # Step 4: send the info on the function call and function response to GPT\n",
        "    # AI가 전달해준 함수 호출 정보\n",
        "    messages.append(response_message)  # extend conversation with assistant's reply\n",
        "    # 시스템이 함수 호출 후 결과 정보\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"function\",\n",
        "            \"name\": function_name,\n",
        "            \"content\": function_response,\n",
        "        }\n",
        "    )  # extend conversation with function response\n",
        "\n",
        "    print(messages)\n",
        "\n",
        "    # 종합 메시지로 ai 메시지 요청\n",
        "    second_response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0613\",\n",
        "        messages=messages,\n",
        "    )  # get a new response from GPT where it can see the function response\n",
        "\n",
        "    # 사용자에게 줄 메시지 출력\n",
        "    print(second_response)\n",
        "    print(second_response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
